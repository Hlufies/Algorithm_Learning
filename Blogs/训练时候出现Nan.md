训练网络loss出现Nan解决办法  

# 一.原因  
一般来说，出现NaN有以下几种情况：  
1. 如果在迭代的100轮以内，出现NaN，一般情况下的原因是因为你的学习率过高，需要降低学习率。可以不断降低学习率直至不出现NaN为止，一般来说低于现有学习率1-10倍即可。  
2. 如果当前的网络是类似于RNN的循环神经网络的话，出现NaN可能是因为梯度爆炸的原因，一个有效的方式是增加“gradient clipping”（梯度截断来解决）  
3. 可能用0作为了除数;
4. 可能0或者负数作为自然对数
5. 需要计算loss的数组越界（尤其是自己，自定义了一个新的网络，可能出现这种情况）
6. 在某些涉及指数计算，可能最后算得值为INF（无穷）（比如不做其他处理的softmax中分子分母需要计算exp（x），值过大，最后可能为INF/INF，得到NaN，此时你要确认你使用的softmax中在计算exp（x）做了相关处理（比如减去最大值等等））
7. 训练深度网络的时候，label缺失问题也会导致loss一直是nan，需要检查label

### 梯度爆炸
原因：梯度变得非常大，使得学习过程难以继续  
现象：观察log，注意每一轮迭代后的loss。loss随着每轮迭代越来越大，最终超过了浮点型表示的范围，就变成了NaN。  
措施：
1. 减小solver.prototxt中的base_lr，至少减小一个数量级。如果有多个loss layer，需要找出哪个损失层导致了梯度爆炸，并在train_val.prototxt中减小该层的loss_weight，而非是减小通用的base_lr。
2. 设置clip gradient，用于限制过大的diff

### 不当的损失函数
原因：有时候损失层中loss的计算可能导致NaN的出现。比如，给InfogainLoss层（信息熵损失）输入没有归一化的值，使用带有bug的自定义损失层等等。  
现象：观测训练产生的log时一开始并不能看到异常，loss也在逐步的降低，但突然之间NaN就出现了。  
措施：看看你是否能重现这个错误，在loss layer中加入一些输出以进行调试。  

### 不当的输入
原因：输入中就含有NaN。  
现象：每当学习的过程中碰到这个错误的输入，就会变成NaN。观察log的时候也许不能察觉任何异常，loss逐步的降低，但突然间就变成NaN了。  
措施：重整你的数据集，确保训练集和验证集里面没有损坏的图片。调试中你可以使用一个简单的网络来读取输入层，有一个缺省的loss，并过一遍所有输入，如果其中有错误的输入，这个缺省的层也会产生NaN。  
