<img width="667" alt="image" src="https://github.com/Hlufies/Algorithm_Learning/assets/130231524/31cf0d52-cb93-44bd-ba4b-2fe1a9234b04">  

# Abstract
随着大型语言模型（LLM）在编写类似人类文本的能力方面不断进步，一个关键的挑战仍然围绕着它们的“幻觉”倾向——生成看似事实但毫无根据的内容。  
# Introduction
大型语言模型（LLM）中的幻觉需要**创建跨越多个主题的事实上错误的信息**。例如，大语言模型的一个基本问题是他们容易产生有关现实世界主题的错误或捏造的细节。这种提供不正确数据的倾向（通常称为幻觉）对该领域的研究人员提出了重大挑战。它会导致 GPT-4 等高级模型和其他同类模型可能生成不准确或完全没有根据的参考。   
出现此问题的原因是训练阶段的**模式生成技术和缺乏实时互联网更新，导致信息输出存在差异**。
## 缓解技术
在当代计算语言学中，减轻幻觉是一个关键焦点。研究人员提出了各种策略来应对这一挑战，包括：  
1. 反馈机制、
2. 外部信息检索
3. 语言模型生成的早期改进
本文通过将这些不同的技术整合和组织成一个综合的分类法而具有重要意义。从本质上讲，本文对大语言模型幻觉领域的贡献有三个方面：   
3.1 Introduction of a systematic taxonomy designed to categorize hallucination mitigation techniques for LLMs, encompassing Vision Language Models (VLMs).  
3.2 Synthesis of the essential features characterizing these mitigation techniques, thereby guiding more structured future research endeavors within this domain.  
3.3 Deliberation on the limitations and challenges inherent in these techniques, accompanied by potential solutions and proposed directions for future research.  
<img width="620" alt="image" src="https://github.com/Hlufies/Algorithm_Learning/assets/130231524/f0ffc51e-905a-4096-919c-70efdea26b3b">

大语言模型中幻觉缓解技术的分类，重点关注涉及**模型开发和提示技术**的流行方法。模型开发分为多种方法，包括新的解码策略、基于知识图的优化、添加新颖的损失函数组件和监督微调。同时，提示工程可以涉及基于检索增强的方法、基于反馈的策略或提示调整。  
### Prompt Engineering
#### Retrieval Augmented Generation Retrieval-Augmented(检索增强生成, RAG)
检索增强生成（RAG）通过利用外部权威知识库而不是依赖可能过时的训练数据或模型的内部知识来增强大语言模型的响应。这种方法解决了大语言模型输出的准确性和通用性的关键挑战（Kang 等人，2023）。 RAG 通过生成不仅相关、当前且可验证的响应，有效缓解了大语言模型的幻觉问题，从而增强了用户信心，并为开发人员提供了一种经济的方式来增强大语言模型在不同应用程序中的保真度和实用性。该系统的缓解技术可以进一步分类为：

##### Before generation
###### LLM-Augmenter(LLM-增强器)
该框架首先从外部知识中检索证据并进行推理以形成证据链。然后，LLM-Augmenter 使用包含 LLM 综合证据的提示查询固定的 LLM (GPT-3.5)，以生成基于外部知识（证据）的候选响应。然后，LLMAugmenter 会验证候选人的回答，例如，通过检查其是否产生幻觉证据。如果是，LLM-Augmenter 会生成反馈消息。该消息用于修改再次查询GPT-3.5的提示。该过程不断迭代，直到候选响应通过验证并发送给用户。
###### FreshPrompt
**解决了大多数大语言模型的静态性质，强调了他们无法适应不断发展的世界**。作者介绍了 FreshQA，一个动态 QA 基准，针对需要当前世界知识的问题和具有错误前提的问题评估大语言模型。通过两种模式的评估，可以测量正确性和幻觉，揭示局限性和改进的需要，特别是在快速变化的知识场景中。为了应对这些挑战，作者提出了 FreshPrompt，这是一种**利用搜索引擎将相关且最新的信息合并到提示中的少量提示方法**。 FreshPrompt 的性能优于竞争方法和商业系统，进一步分析强调了检索证据的数量和顺序对正确性的影响。这项工作对大语言模型适应不断发展的知识的能力进行了详细评估，引入了 FreshQA 数据集和有效的提示方法 FreshPrompt，以增强动态问答能力。
##### During generation
以下技术演示了逐句级别的知识检索，其中模型在生成每个句子时进行信息检索  
###### Knowledge Retrieval 知识检索
在幻觉出现时积极检测和减少幻觉。在继续创建句子之前，该方法首先使用模型的 logit 输出值来识别可能的幻觉，验证它们是否准确，然后减轻发现的任何幻觉。最重要的认识是，在生成过程中处理幻觉至关重要，因为当模型之前在其输出中经历过幻觉时，它会提高生成带有幻觉的句子的概率。这项研究调查了 Logit 输出值（由 GPT-3 等模型产生）在幻觉识别中的使用。然而，它承认某些仅通过 API 调用可用的模型可能不会给出 logit 输出值，并强调该信息是补充来源，而不是幻觉检测方法的必要先决条件。该方法使用检索到的知识作为纠正阶段的支持，指示模型通过消除或替换幻觉信息来修复短语，以减少所创建句子中的幻觉。
###### Decompose and Query framework 分解和查询框架（D&Q）
他们提出了 D&Q 框架来指导模型利用外部知识，同时将推理限制在可靠信息上，从而减轻幻觉的风险。实验结果证明了 D&Q 的有效性，在 ChitChatQA 上展示了与 GPT-3.5 的竞争性能，并在 HotPotQA 上取得了值得注意的 59.6% F1 分数（仅问题）。该框架涉及一个无需工具调用的监督微调阶段，并且在预测阶段，该模型使用外部工具来查询可靠的问答库，允许回溯并在需要时启动新的搜索。研究结果强调了 D&Q 在提高大语言模型在问答任务中的鲁棒性和表现方面的潜力。
###### Real-time Verification and Rectification (EVER)
大语言模型经常面临制作不准确或幻觉内容的挑战，尤其是在推理任务中。对此作出回应基于非检索和检索增强生成方法中普遍存在的问题（Kang 等人，2023）引入了 EVER 框架。与现有的事后纠正幻觉的方法不同，EVER 在生成过程中采用实时、逐步的策略来检测和纠正幻觉。这三个阶段的过程涉及生成、验证和纠正，有效识别和纠正内在和外在的幻觉。 EVER 的性能优于基于检索和非检索的基线，在跨不同任务（例如简短的 QA、传记生成和多跳推理）生成可信且准确的文本方面展示了显着改进。该框架的功效经过实证验证，证明了其缓解幻觉“滚雪球”问题的能力，使其对提高大语言模型的准确性和可靠性做出了宝贵贡献。
##### After generation
###### Retrofit Attribution using Research and Revision (RARR)
在大语言模型领域，各项任务都取得了显着的进步；然而，问题仍然存在，例如生成的内容没有适当的支持或准确性。由于缺乏可归因性，确定大语言模型输出的可信度面临挑战，促使引入 RARR。简介中介绍的这个与模型无关的系统可以自动执行任何文本生成模型的归因过程。受到事实核查工作流程的启发，RARR 进行研究和后期编辑，使内容与检索到的证据保持一致，同时保留原始质量，在大语言模型生成后无缝运行。引言中概述的贡献包括正式化归因编辑任务、引入新指标、对现有修订模型进行基准测试以及提出研究和修订模型。结论强调了 RARR 在保留基本文本属性的同时增强归因的能力，为增强 LLM 输出的可靠性提供了实用的解决方案。
###### High Entropy Word Spotting and Replacement
虽然检测高熵词的技术可行性可能是显而易见的，但由于闭源性质，出现了重大挑战许多当代的大语言模型，基于订阅的 API 限制了可访问性。 (Rawte et al., 2023) 提出的解决方案涉及利用开源大语言模型来识别高熵词，然后使用基于较低幻觉漏洞指数的大语言模型进行替换。结果强调了 albert-large-v2（Lan 等人，2020）在检测 GPT-3 生成内容中的高熵词方面的卓越性能。相反，distilroberta-base (Sanh et al., 2019) 在替换高熵词方面表现出优越的性能，从而减少幻觉。这种方法的一个不可或缺的方面是将连续的高熵单词视为一个统一的单元，这些单词在替换之前被集体屏蔽，事实证明在解决与生成傀儡或首字母缩略词歧义相关的幻觉方面特别有效。
##### End-to-End RAG
论文中提出的RAG端到端过程涉及将预训练的序列到序列 (seq2seq) 转换器与维基百科的密集向量索引集成，可通过 Dense Passage 访问猎犬（DPR）。这种创新的组合允许模型根据输入查询和 DPR 提供的潜在文档来调节其输出生成。在此过程中，DPR充当神经检索器，根据输入提供相关文档。然后，seq2seq模型（特别是BART）使用这些文档来生成最终输出。该模型采用top-K近似来边缘化这些潜在文档，这可以在每个输出的基础上（假设一个文档负责所有标记）或每个标记的基础上完成（允许不同的文档影响该文档的不同部分）。

 
