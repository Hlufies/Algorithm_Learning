随着语言模型容量的不断增大，如从GPT-2，RoBERTa-L到GPT-3，可训练参数量已增长到175B。如果要微调以适应下游任务，如此大的参数量对于时间和显存要求都带来很大的挑战。  

然而，现存的两种显著范式为了规避这一问题，存在一些不足:  
1. 增加adapter：主要问题在于推理时带来的额外计算量和延迟
2. 优化prompt： 前缀微调(Prefix Tuning)较难优化，而且随着参数量增长性能并非单调变化。


## 什么是lora？
```
lora是大模型的低秩适配器，或者就简单的理解为适配器，在图像生成中可以将lora理解为某种图像风格（比如SD社区中的各种漂亮妹子的lora，可插拔式应用，甚至组合式应用实现风格的融合）的适配器，在NLP中可以将其理解为某个任务的适配器（比如最近各种开源chatgpt复现中使用的lora技术，不过限于文本领域的特性，目前组合式应用似乎还不多）。
```
## lora 是 怎么做的呢
```
说了这么多：那 lora 是 怎么做的呢？

在原模型旁边增加一个旁路，通过低秩分解（先降维再升维）来模拟参数的更新量；
训练时，原模型固定，只训练降维矩阵A和升维矩阵B；
推理时，可将BA加到原参数上，不引入额外的推理延迟；
初始化，A采用高斯分布初始化，B初始化为全0，保证训练开始时旁路为0矩阵；
可插拔式的切换任务，当前任务W0+B1A1，将lora部分减掉，换成B2A2，即可实现任务切换
```
## lora 为什么可以这样做？
```
听着云里雾里：lora 为什么可以这样做？

前人的工作中[1][2]发现过度参数化的模型实际上位于一个低内在维度的空间，因此作者提出假设，微调时权重的变化同样有一个低的"内在维度"，因此可以进行低秩矩阵分解。
```
## 用一句话描述 lora  
固定大模型，增加低秩分解的矩阵来适配下游任务。
## lora 优点是什么
```
一个中心模型服务多个下游任务，节省参数存储量
推理阶段不引入额外计算量
与其它参数高效微调方法正交，可有效组合
训练任务比较稳定，效果比较好
```
## Lora缺点
```
生成任务上效果 欠佳
```
