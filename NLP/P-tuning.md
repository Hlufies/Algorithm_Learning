# Motivation
之前大模型的范式:  
1. Pretrain  
2. Fine-tuning  
```
这种方案，需要对于每个任务都重新 fine-tune 一个新的模型，且不能共用。
但是对于一个预训练的大语言模型来说，这就仿佛好像是对于每个任务都进行了定制化，十分不高效。
是否存在一种方式，可以将预训练语言模型作为电源，不同的任务当作电器，仅需要根据不同的电器（任务），选择不同的插座，对于模型来说，即插入不同的任务特定的参数，就可以使得模型适配该下游任务。
```
**Prompt Learning**就是这个适配器，它能高效得进行预训练语言模型的使用。
```
这种方式大大地提升了预训练模型的使用效率，如下图：
左边是传统的 Model Tuning 的范式：对于不同的任务，都需要将整个预训练语言模型进行精调，每个任务都有自己的一整套参数。
右边是Prompt Tuning，对于不同的任务，仅需要插入不同的prompt 参数，每个任务都单独训练Prompt 参数，不训练预训练语言模型，这样子可以大大缩短训练时间，也极大的提升了模型的使用率。
```
<img width="813" alt="image" src="https://github.com/Hlufies/Algorithm_Learning/assets/130231524/6cdf5a50-a9d5-4222-9cfe-fdd813cbf77d">
