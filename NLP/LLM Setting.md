LLMs 的输出受超参数配置（configuration hyperparameters）影响，它能控制模型的多个方面，例如有多「随机」。调整超参数能生成更具活泼、多样及有趣的输出。本章将讨论两个重要的超参数以及它们如何影响 LLMs。  
<img width="190" alt="image" src="https://github.com/Hlufies/Algorithm_Learning/assets/130231524/6c24820b-e529-4e5f-9df4-05444aa4c548">

## Temperature
热度可以控制语言模型输出的随机度。  
高热度生成更难预料及富有创造性的结果，低热度则更保守。  
**例如热度为 0.5 时模型生成内容将比 1.0 更容易预测且创造性更少。**

## Top-K
```
Top p，即核心采样（nucleus sampling），是另一个控制语言模型输出随机性的超参数配置。
它设定了一个概率阈值，并选择累积概率超过该阈值的最佳词汇，然后模型从这组词汇中随机抽取以生成输出。
与传统方法（在整个词汇表中随机抽样）相比，这种方法可以产生更丰富多样且有趣的输出。
例如 top p 为 0.9 时模型将仅考虑概率阈值 90% 以上的词汇。
```
## 其他
```
还有许多其他超参数会影响语言模型的表现，如频率（frequency）和存在惩罚（presence penalties）。这里暂时不涉及它们，但也许将来会。
```
