# Lora的具体操作
即在原始的预训练模型旁边增加一个新的通路，通过前后两个矩阵A,B相乘，做一个降维再升维的操作。外挂层和预训练模型层维度都为d,A会先将维度d降维到r，B再升回d。一般是针对Q/K/V的投影矩阵W分解成低秩矩阵BA作为外挂，B·以0初始化，A以高斯分布初始化。
# 为什么可以用LORA
专有任务的微调权重与初始预训练权重之间的差异往往表现出**低固有秩 (low intrinsic rank)差异**，这意味着它可以很好地近似为一个低秩矩阵。即微调权重和初始预训练权重之间的这种差距可以表示为两个较小矩阵的乘积
# LORA的参数
1. rank秩8:选择更高秩的分解矩阵将抵消LORA的效率优势，而且设到16也差别不大
2. Alpha:16。Alpha用于对学习到的权重进行扩展。通常建议固定Alpha的值为16，不调节。
3. 目标模块: 所有密集层。初始只对QV，但应用所有有效日更接近全参数。
4. 基础学习率: 1e-4。只有当训练不稳定时降到3e-E2
# Lora和全参数相比
1. 对普通文本任务如生成sql差别不大，对小模型推理影响很多，但到70B的时候差别不大。此外，数据偏离分布外太远可能会导致LORA难以处理，有提示对LORA训练更稳定，没有提示用特殊词元代替 (需训练比如4个特殊start/end等)
2. LORA虽然在内存方面十分高效，但可能会影响模型达到收敛的速度。
