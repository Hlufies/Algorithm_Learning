1. [AUC的两种公式是?证明这两种等价的吗？]()
2. [多Loss平衡](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/%E5%A4%9ALoss%E5%B9%B3%E8%A1%A1.md)
3. [训练时出现nan](https://github.com/Hlufies/Algorithm_Learning/blob/main/Blogs/%E8%AE%AD%E7%BB%83%E6%97%B6%E5%80%99%E5%87%BA%E7%8E%B0Nan.md)
4. [似然函数推到交叉熵]()
5. [梯度下降](https://zhuanlan.zhihu.com/p/418345156)
6. [embedding模型原理, 常见的embedding模型结构(双塔)](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/embedding%E7%9A%84%E5%8E%9F%E7%90%86.md)
7. [损失函数](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.md)
8. [激活函数](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.md)
9. [scale-up（维数，方差）](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/Transformer_scale.md)
10. [Transformer面试题](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/Transformer%E9%9D%A2%E8%AF%95%E9%A2%98.md)
11. [numpy写线性回归的sgd，（前向，反向，自定义batch）](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/numpy%E5%86%99%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84sgd(%E5%89%8D%E5%90%91%EF%BC%8C%E5%8F%8D%E5%90%91%EF%BC%8C%E8%87%AA%E5%AE%9A%E4%B9%89batch).md)
12. [GPT面试题](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/GPT.md)
13. [Bert面试题](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/Bert%E9%9D%A2%E8%AF%95%E9%A2%98.md)
14. [基于RM模型使用PPO算法微调SFT模型，不收敛咋办](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/%E5%9F%BA%E4%BA%8ERM%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8PPO%E7%AE%97%E6%B3%95%E5%BE%AE%E8%B0%83SFT%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%B8%8D%E6%94%B6%E6%95%9B%E5%92%8B%E5%8A%9E.md)
15. [对比学习-simCSE，infoNCE]()
16. [不太懂？如何平衡不同tokenizer的不同粒度]()
17. [tokenizer的切词方法](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/tokenizer%E7%9A%84%E5%88%87%E8%AF%8D%E6%96%B9%E6%B3%95.md)
18. [大模型训练的损失是什么?](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%9A%84%E6%8D%9F%E5%A4%B1%E6%98%AF%E4%BB%80%E4%B9%88.md)
19. [位置编码有哪几种](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81.md)
20. [layer normalization有哪几种位置上的结构?](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/layer%20normalization%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D%E4%BD%8D%E7%BD%AE%E4%B8%8A%E7%9A%84%E7%BB%93%E6%9E%84.md)
21. [python中__init.py的作用](https://www.jianshu.com/p/73f7fbf75183)
22. [sys.append.path](https://www.cnblogs.com/hls-code/p/15337302.html)
23. [layer normalization方法有哪些?]()
24. [Dreambooth]()
25. [Lora](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/Lora.md)
26. [Prefix Tuning]()
27. [Prompts Tuning]()
28. [P Tuning]()
29. [各种Norm]()
30. [GNN, 项目内容里面的]()
31. [Clip](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/CLIP.md)
32. [BLIP]()
33. [对比学习]()
34. [训练步骤, forward, backward, zero]()
35. [GPT和Bert的差异]()
36. [目前有几种流行的大模型架构]()
37. [Prefix LM 和casual LM的区别]()
38. [RLHF流程]()
39. [instruct tuning 和 prompt tuning 的区别]()
  
40. []
41. [华为面试]
42. [商汤面试1](https://github.com/Hlufies/Algorithm_Learning/blob/main/%E9%9D%A2%E7%BB%8F/%E5%95%86%E6%B1%A4%E9%9D%A2%E8%AF%951.md)
```
华为面试 算法题考的是鸡之间的距离
l1 l2正则跟随机变量分布有关
```
