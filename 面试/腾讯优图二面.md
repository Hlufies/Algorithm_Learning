1. 介绍一下论文
3. Diffusion和之前生成式模型的优缺点  
   1. https://blog.csdn.net/GarryWang1248/article/details/134950814
   2. http://arthurchiao.art/blog/rise-of-diffusion-based-models-zh/
4. EM 和 VAE的使用条件区别
   1. https://blog.csdn.net/WeiDelight/article/details/89485144
6. 重参数  p(x) 和 p(y)的概率密度之间的关系
   1. https://blog.csdn.net/u014386899/article/details/136473733
8. Diffusion 生成原理
9. Diffusion 条件控制有哪些 (DIT 有增加的一些条件控制原理)
10. 训练更新的具体步骤 从梯度的角度 梯度更新

https://qzq2514.github.io/2024/03/10/Diffusion%E5%AD%A6%E4%B9%A07-DiT/

在扩散模型（Diffusion Models）中，\( p(x) \) 和 \( p(y) \) 的概率密度之间的关系通常涉及到数据点 \( x \) 和潜在变量 \( y \) 的联合分布和条件分布。扩散模型是通过引入一个逐渐增加噪声的过程，将数据分布 \( p(x) \) 转化为标准高斯分布 \( p(y) \)，然后再通过逆过程从高斯分布还原数据分布。

一般地，在扩散模型中，\( x \) 表示观测数据，\( y \) 表示在扩散过程中特定时间步的潜在变量。这个过程可以描述为：

1. **前向过程（Forward Process）：** 从数据 \( x \) 开始，通过逐步增加噪声，将其转化为 \( y \)。这个过程可以表示为：
   $\[
   p(y|x) = \mathcal{N}(y; \sqrt{\alpha_t} x, (1-\alpha_t) I)
   \]$
   其中 \( \alpha_t \) 是控制噪声大小的参数，随时间步 \( t \) 变化。

2. **后向过程（Reverse Process）：** 从标准高斯分布的 \( y \) 开始，通过去噪还原出数据 \( x \)。这个过程的逆向等价于：
   $\[
   p(x|y) = \mathcal{N}(x; \mu_t(y), \sigma_t^2 I)
   \]$
   其中 \( \mu_t(y) \) 和 \( \sigma_t \) 是与时间步 \( t \) 相关的均值和方差，通常通过神经网络来近似。

在扩散模型的框架中，我们有以下关系：

- \( p(x) \) 是观测数据的真实分布。
- \( p(y) \) 是经过噪声处理后的数据分布，通常被处理成标准高斯分布 \( \mathcal{N}(0, I) \)。

因此，前向过程实际上定义了一个从数据分布 \( p(x) \) 到潜在变量分布 \( p(y) \) 的转换规则，而后向过程则定义了一个从潜在变量分布 \( p(y) \) 回到数据分布 \( p(x) \) 的生成规则。

在训练扩散模型时，目标是通过前向过程逐步添加噪声并在逆向过程中学会去噪，从而在生成数据时能够从简单的噪声分布（通常是标准高斯分布）中抽样并还原出符合真实数据分布的样本。

总结起来，\( p(x) \) 和 \( p(y) \) 之间的关系在扩散模型中可以理解为一个从数据分布到噪声分布的转换（前向过程）以及从噪声分布到数据分布的还原（后向过程），这些过程都是通过特定的概率密度函数和参数来描述的。
